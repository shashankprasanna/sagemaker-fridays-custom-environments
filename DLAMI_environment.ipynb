{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "scheduled-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "DEPTH = 3\n",
    "NUM_CLASSES = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "established-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_example_parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.io.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.io.decode_raw(features['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    \n",
    "    image = train_preprocess_fn(image)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "agreed-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess_fn(image):\n",
    "\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\n",
    "    image = tf.image.random_crop(image, [HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seasonal-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames, batch_size):\n",
    "    \"\"\"Read the images and labels from 'filenames'.\"\"\"\n",
    "    # Repeat infinitely.\n",
    "    dataset = tf.data.TFRecordDataset(filenames).repeat().shuffle(10000)\n",
    "\n",
    "    # Parse records.\n",
    "    dataset = dataset.map(single_example_parser, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Batch it up.\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ongoing-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape, learning_rate, weight_decay, optimizer, momentum):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = keras.applications.resnet50.ResNet50(include_top=False,\n",
    "                                                          weights='imagenet',\n",
    "                                                          input_tensor=input_tensor,\n",
    "                                                          input_shape=input_shape,\n",
    "                                                          classes=None)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "federal-congress",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "156/156 [==============================] - 14s 58ms/step - loss: 1.8886 - accuracy: 0.4023 - val_loss: 1.4213 - val_accuracy: 0.5193\n",
      "Epoch 2/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 1.1634 - accuracy: 0.5996 - val_loss: 1.1757 - val_accuracy: 0.6062\n",
      "Epoch 3/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.9752 - accuracy: 0.6638 - val_loss: 1.0203 - val_accuracy: 0.6507\n",
      "Epoch 4/15\n",
      "156/156 [==============================] - 8s 51ms/step - loss: 0.8778 - accuracy: 0.6921 - val_loss: 0.8820 - val_accuracy: 0.6960\n",
      "Epoch 5/15\n",
      "156/156 [==============================] - 8s 51ms/step - loss: 0.7991 - accuracy: 0.7226 - val_loss: 0.8770 - val_accuracy: 0.6993\n",
      "Epoch 6/15\n",
      "156/156 [==============================] - 8s 51ms/step - loss: 0.7388 - accuracy: 0.7415 - val_loss: 0.8069 - val_accuracy: 0.7206\n",
      "Epoch 7/15\n",
      "156/156 [==============================] - 8s 51ms/step - loss: 0.6956 - accuracy: 0.7569 - val_loss: 0.7899 - val_accuracy: 0.7233\n",
      "Epoch 8/15\n",
      "156/156 [==============================] - 8s 51ms/step - loss: 0.6577 - accuracy: 0.7707 - val_loss: 0.7615 - val_accuracy: 0.7387\n",
      "Epoch 9/15\n",
      "156/156 [==============================] - 8s 52ms/step - loss: 0.6296 - accuracy: 0.7799 - val_loss: 0.7601 - val_accuracy: 0.7404\n",
      "Epoch 10/15\n",
      "156/156 [==============================] - 8s 53ms/step - loss: 0.5980 - accuracy: 0.7887 - val_loss: 0.7203 - val_accuracy: 0.7495\n",
      "Epoch 11/15\n",
      "156/156 [==============================] - 8s 53ms/step - loss: 0.5716 - accuracy: 0.7984 - val_loss: 0.7211 - val_accuracy: 0.7524\n",
      "Epoch 12/15\n",
      "156/156 [==============================] - 8s 54ms/step - loss: 0.5538 - accuracy: 0.8047 - val_loss: 0.7032 - val_accuracy: 0.7631\n",
      "Epoch 13/15\n",
      "156/156 [==============================] - 8s 53ms/step - loss: 0.5275 - accuracy: 0.8159 - val_loss: 0.7069 - val_accuracy: 0.7603\n",
      "Epoch 14/15\n",
      "156/156 [==============================] - 8s 54ms/step - loss: 0.5109 - accuracy: 0.8182 - val_loss: 0.6974 - val_accuracy: 0.7623\n",
      "Epoch 15/15\n",
      "156/156 [==============================] - 8s 53ms/step - loss: 0.4836 - accuracy: 0.8286 - val_loss: 0.6904 - val_accuracy: 0.7678\n",
      "39/39 [==============================] - 1s 19ms/step - loss: 0.6912 - accuracy: 0.7664\n",
      "Test loss    : 0.6911723017692566\n",
      "Test accuracy: 0.7664262652397156\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "epochs       = 15\n",
    "lr           = 0.001\n",
    "batch_size   = 256\n",
    "momentum     = 0.9\n",
    "weight_decay = 2e-4\n",
    "optimizer    = 'sgd'\n",
    "model_type   = 'resnet'\n",
    "\n",
    "training_dir   = 'dataset'\n",
    "validation_dir = 'dataset'\n",
    "eval_dir       = 'dataset'\n",
    "\n",
    "train_dataset = get_dataset(training_dir+'/train.tfrecords',  batch_size)\n",
    "val_dataset   = get_dataset(validation_dir+'/validation.tfrecords', batch_size)\n",
    "eval_dataset  = get_dataset(eval_dir+'/eval.tfrecords', batch_size)\n",
    "\n",
    "input_shape = (HEIGHT, WIDTH, DEPTH)\n",
    "model = get_model(input_shape, lr, weight_decay, optimizer, momentum)\n",
    "\n",
    "# Optimizer\n",
    "if optimizer.lower() == 'sgd':\n",
    "    opt = SGD(lr=lr, decay=weight_decay, momentum=momentum)\n",
    "else:\n",
    "    opt = Adam(lr=lr, decay=weight_decay)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_dataset, steps_per_epoch=40000 // batch_size,\n",
    "                    validation_data=val_dataset, \n",
    "                    validation_steps=10000 // batch_size,\n",
    "                    epochs=epochs)\n",
    "\n",
    "\n",
    "# Evaluate model performance\n",
    "score = model.evaluate(eval_dataset, steps=10000 // batch_size, verbose=1)\n",
    "print('Test loss    :', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-tiger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p38)",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
