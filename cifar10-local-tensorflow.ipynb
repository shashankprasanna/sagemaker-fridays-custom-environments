{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f7e0c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 11:17:52.805121: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "DEPTH = 3\n",
    "NUM_CLASSES = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa59ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_example_parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.io.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.io.decode_raw(features['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    \n",
    "    image = train_preprocess_fn(image)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db0ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess_fn(image):\n",
    "\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\n",
    "    image = tf.image.random_crop(image, [HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9e07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames, batch_size):\n",
    "    \"\"\"Read the images and labels from 'filenames'.\"\"\"\n",
    "    # Repeat infinitely.\n",
    "    dataset = tf.data.TFRecordDataset(filenames).repeat().shuffle(10000)\n",
    "\n",
    "    # Parse records.\n",
    "    dataset = dataset.map(single_example_parser, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Batch it up.\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97bc5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape, learning_rate, weight_decay, optimizer, momentum):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = keras.applications.resnet50.ResNet50(include_top=False,\n",
    "                                                          weights='imagenet',\n",
    "                                                          input_tensor=input_tensor,\n",
    "                                                          input_shape=input_shape,\n",
    "                                                          classes=None)\n",
    "    x = Flatten()(base_model.output)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d1ff34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "2022-09-21 11:15:47.135119: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "FloatProgress(value=0.0)\n",
      ">> Downloading cifar-10-python.tar.gz \n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Generating cifar10-dataset/train.tfrecords\n",
      "Generating cifar10-dataset/validation.tfrecords\n",
      "Generating cifar10-dataset/eval.tfrecords\n",
      "Removing original files.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python generate_cifar10_tfrecords.py --data-dir=cifar10-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a049c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p39/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "epochs       = 15\n",
    "lr           = 0.001\n",
    "batch_size   = 256\n",
    "momentum     = 0.9\n",
    "weight_decay = 2e-4\n",
    "optimizer    = 'sgd'\n",
    "model_type   = 'resnet'\n",
    "\n",
    "training_dir   = 'cifar10-dataset'\n",
    "validation_dir = 'cifar10-dataset'\n",
    "eval_dir       = 'cifar10-dataset'\n",
    "\n",
    "train_dataset = get_dataset(training_dir+'/train.tfrecords',  batch_size)\n",
    "val_dataset   = get_dataset(validation_dir+'/validation.tfrecords', batch_size)\n",
    "eval_dataset  = get_dataset(eval_dir+'/eval.tfrecords', batch_size)\n",
    "\n",
    "input_shape = (HEIGHT, WIDTH, DEPTH)\n",
    "model = get_model(input_shape, lr, weight_decay, optimizer, momentum)\n",
    "\n",
    "# Optimizer\n",
    "if optimizer.lower() == 'sgd':\n",
    "    opt = SGD(lr=lr, decay=weight_decay, momentum=momentum)\n",
    "else:\n",
    "    opt = Adam(lr=lr, decay=weight_decay)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_dataset, steps_per_epoch=40000 // batch_size,\n",
    "                    validation_data=val_dataset, \n",
    "                    validation_steps=10000 // batch_size,\n",
    "                    epochs=epochs)\n",
    "\n",
    "\n",
    "# Evaluate model performance\n",
    "score = model.evaluate(eval_dataset, steps=10000 // batch_size, verbose=1)\n",
    "print('Test loss    :', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7808b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p39)",
   "language": "python",
   "name": "conda_tensorflow2_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
